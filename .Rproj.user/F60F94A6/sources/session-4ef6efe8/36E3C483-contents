---
title: "<br> Multi-Object Tracking livestock method driven by foundation models in computer vision using UAV videos"
author: '<span style="color: black"> Responsible  Professor: </span> Kooistra Lammert &emsp; <span style ="color:black"> Supervisor: </span> João Valente    <br> <span style="color:black"> Student: </span> Ricardo Ruiz Sánchez'
date: "2024-06-19"
institute: University of Utrecht
date-format: long
lightbox: true
format: 
  revealjs:
    css: styles.scss
    toc: true
    toccolor: red
    incremental: false
    toc-depth: 1
    slide-number: true
    progress: true
    title-slide-attributes:
      data-background-image: "background_thesis_0.jpg"
      data-background-size: contain
      data-background-opacity: "number"
    toc-title: Content
    chalkboard: true
    logo: logo_gima.png
    output-file: gima_thesis_jordi.html
---

# Introduction {background-image="background_thesis.jpg"}

::: incremental
<font color='#525659'>

-   What is the topic?
-   Why is it important?
-   What needs to be done?

</font>
:::

## Context {.smaller .incremental background-image="background_thesis.jpg"}

::: panel-tabset
### European Green Deal {background-image="background_thesis.jpg"}

::: columns
::: {.column .incremental width="60%"}
[It is the EU's strategy for reaching the 2050 goal.Europe's future depends on a healthy planet]{style="color:#525659"}

-   Support sustainable food production
-   Promoting sustainable forest management
-   Better monitoring of biodiversity progress
:::

::: {.column width="40%"}
![Source: Ricardo Ruiz Sánchez](green_deal.png){.lightbox}
:::

::: footer
Introduction
:::
:::

### SAID lab {background-image="background_thesis.jpg"}

::: columns
::: {.column .incremental width="60%"}
[Leverage the interaction between people and airborne technology]{style="color:#525659"}

-   Application of drone services in real-world scenarios
-   Employment of autonomous and more intelligent vehicles for remote sensing the environment
:::

::: {.column width="40%"}
[![Social Artificial Intelligent Drones (SAID) Lab](said_lab.png)](https://www.wur.nl/en/newsarticle/wageningen-university-research-starts-social-drones-lab.htm)
:::

::: footer
Introduction
:::
:::

### ICAERUS {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column .incremental width="60%"}
[Monitoring grazing herds is challenging and time consuming]{style="color:#525659"}

-   Explore the capacity of drone monitoring for reducing labour intensity and improving work conditions
-   Observing the impact on cattle and sheep herd behaviour
:::

::: {.column width="40%"}
[![ICAERUS use case of livestock monitoring](iceaerus_livestock.png)](https://icaerus.eu/use-cases/livestock-monitoring-uc/)
:::

::: footer
Introduction
:::
:::
:::

## Field of domain {.smaller .incremental background-image="background_thesis.jpg"}

::: panel-tabset
### Precision livestock {.incremental}

::: columns
::: {.column .incremental width="50%"}
Technology provides better management strategies:

-   Automation of milking robots
-   Implementation of oestrus detection
-   Radio frequency tags and Accelerometers
-   Images obtained by UAV and processed by artificial intelligence have been used to count livestock
:::

::: {.column width="50%" layout="[[-1], [1], [-1]]"}
![](c_rrs.JPG)
:::

::: footer
Introduction
:::
:::

### Opportunity

Initiatives such as "Open2Preserve", which reduces fire risks by guided grazing are an opportunity to bring a positive impact using livestock

![[Link](https://open2preserve.eu/en/noticies/proyecto-open2preserve-desarrollo-de-modelos-de-gestion-sostenible-que-disminuyan-el-riesgo-de-incencios-en-espacios-abiertos-de-montana/)](open2preserve.png)

### Threat

::: columns
::: {.column width="50%"}
<br> <br> <br>

A new study by the University of Liverpool has found that sheep grazing does negatively affect the diversity of plant species of upland areas of the British countryside, and it could take up to 60 years to recover.
:::

::: {.column width="50%" layout="[[-1], [1], [-1]]"}
![[Link](https://onlinelibrary.wiley.com/doi/10.1111/aab.12591)](threat_livestock.png){width="35%"}
:::

::: footer
Introduction
:::
:::
:::

## Economical impact {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column width="40%"}
Depredation by large carnivore species in Europa such as wolves (*Canis Lupus* Linneus 1758) is one threat of missing sheep. <br>

![(Rančić et al., 2023)](economic_depradation.png){fig-align="center"}
:::

::: {.column width="60%"}
The current manual system to count livestock could be yielding an annual loss of AUD 12,000,0000

![(Gervasi et al., 2021)](goats_all.jpeg){fig-align="center"}
:::
:::

## Research questions {.smaller background-image="background_thesis.jpg"}

::: panel-tabset
### Research framework {background-image="background_thesis.jpg"}

![](research_framework.png){width="80%"}

### 1st RQ {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column .nonincremental width="40%"}
<br> <br> <br>

-   What are the opportunities for multi-object tracking systems to count livestock with supervised or self-supervised learning methods?
:::

::: {.column width="60%" layout="[[-1], [1], [-1]]"}
![Source: Ricardo Ruiz Sánchez](goal_1_full.png){.r-stretch fig-align="center"}
:::

::: footer
Introduction
:::
:::

### 2nd RQ {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column .nonincremental width="40%"}
<br> <br> <br>

-   How do the state-of-the-art foundation models (self-supervised) perform, when compared to previous supervised neural networks such as YOLOv8 measured by counting metrics like MAE or NAE?
:::

::: {.column width="60%" layout="[[-1], [1], [-1]]"}
![Source: Ricardo Ruiz Sánchez](goal_2_full.png){.r-stretch fig-align="center"}
:::

::: footer
Introduction
:::
:::

### 3rd RQ {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column .nonincremental width="40%"}
<br> <br> <br>

-   What is the model's performance on livestock counting under different weather conditions and scenarios? How much does the model generalise?
:::

::: {.column width="60%" layout="[[-1], [1], [-1]]"}
![Source: Ricardo Ruiz Sánchez](goal_3_full.png){.r-stretch fig-align="center"}
:::

::: footer
Introduction
:::
:::
:::

## Objectives {background-image="background_thesis.jpg"}

[Conceptual design]{style="color:#525659"}

![](conceptual_design.png){fig-align="center"}

::: footer
Introduction
:::

## Literature Review {.smaller background-image="background_thesis.jpg"}

::: panel-tabset
### Supervised plot {background-image="background_thesis.jpg"}

```{r}
#| echo: false
#| output-location: slide
library(highcharter)
library(dplyr)
library(lubridate)
supervised_literature <- read.csv2("articles_supervised_v02.csv", sep=",")
supervised_articles <- arrange(supervised_literature, date)

supervised_articles <-  supervised_articles %>% mutate(id=seq(1,22,1))
supervised_articles$date <- as.Date(supervised_articles$date)
supervised_articles$relevant <- supervised_articles$relevant |> recode(yes = "Relevant",
                            no ="Non-relevant") 
hchart(supervised_articles, "point", hcaes(x=date, y=id, group=relevant))|>
  hc_title(text="22 Articles related to supervised learning") |>
  hc_subtitle(text= "11 Relevant articles for livestock detection",
              style= list(color="#a10d25")) |> 
  hc_xAxis(title=list(text="Date"))|>
  hc_yAxis(title=list(text="id")) |>
  hc_credits(text="Literature review for MSc GIMA 2024") |>
  hc_tooltip(formatter=JS("function(){
                           return ('<b>Title: </b>' + this.point.title +' <br> <b> Author:</b> ' + this.point.article + ' <br> <b>Date:</b> ' + Highcharts.dateFormat('%Y-%m-%d', this.x));}")) |> 
  hc_legend(align= "right",
            floating =TRUE) |> 
  hc_colors(c("#82878b","#a10d25")) 
```

::: footer
Introduction
:::

### Supervised table {.smaller background-image="background_thesis.jpg"}

```{r}
#| echo: false
#| output-location: slide
library(DT)
library(tidyverse)
supervised_literature_tbl <- supervised_articles |> arrange(date)
supervised_literature_tbl$doi <- paste0('<a href="', supervised_articles$doi, '">', 'Link to article: ',supervised_articles$id, '</a>')
supervised_literature_tbl |> 
  select(c(title,date,article,relevant,doi)) |>
  rename(Title = title,
         Date = date,
         Citation = article,
         Relevant = relevant,
         DOI = doi) |> 
DT::datatable(
              filter = "top",
              options=list(
                          columnDefs = list(list(className = 'dt-center', targets = c(2:4))),
                          pageLength = 2),
              escape = FALSE) |>
  DT::formatStyle(columns = c(1, 2, 3, 4, 5), fontSize = '75%')
  
```

### Self-supervised plot {background-image="background_thesis.jpg"}

```{r}
#| echo: false
#| output-location: slide
library(highcharter)
library(dplyr)
library(lubridate)
self_supervised_articles <- read.csv2("articles_self_supervised.csv", sep=",")
self_supervised_articles_sorted <- arrange(self_supervised_articles, date)
self_supervised_articles_sorted <-  self_supervised_articles_sorted %>% mutate(id=seq(1,23,1))
self_supervised_articles_sorted$date <- as.Date(self_supervised_articles_sorted$date)
self_supervised_articles_sorted$type <- self_supervised_articles_sorted$type |>
                                      recode(yes = "Relevant", no ="Non-relevant") 
self_supervised_articles_sorted <- self_supervised_articles_sorted |>
  rename(relevant=type)
hchart(self_supervised_articles_sorted, "point", hcaes(x=date, y=id, group=relevant)) |>
  hc_title(text="23 Articles related to foundational models") |>
  hc_subtitle(text= "10 Articles relevant for this project",
              style= list(color="#0058a3")) |> 
  hc_xAxis(title=list(text="Date")) |>
  hc_yAxis(title=list(text="id")) |>
  hc_credits(text="Literature review for MSc GIMA 2024") |>
  hc_tooltip(formatter=JS("function(){
                           return ('<b>Title: </b>' + this.point.title +' <br> <b>Author:</b> ' + this.point.article + ' <br> <b>Date:</b> ' + Highcharts.dateFormat('%Y-%m-%d', this.x));
                         }")) |> 
  hc_legend(align= "right",
            floating =TRUE) |> 
  hc_colors(c("#82878b","#0058a3")) 
```

::: footer
Introduction
:::

### Self-supervised table {.smaller background-image="background_thesis.jpg"}

```{r}
#| echo: false
#| output-location: slide
library(DT)
library(tidyverse)
unsupervised_literature_tbl <- self_supervised_articles_sorted|> 
  select(c(title,date,article,relevant,doi,id)) |>
  rename(Title = title,
         Date = date,
         Citation = article)
unsupervised_literature_tbl$DOI <- paste0('<a href="', unsupervised_literature_tbl$doi, '">', 'Link to article: ', unsupervised_literature_tbl$id, '</a>')
unsupervised_literature_tbl |>
  select(-c(doi, id)) |> 
DT::datatable(
              filter = "top",
              options=list(
                          columnDefs = list(list(className = 'dt-center', targets = c(2:4))),
                          pageLength = 2),
              escape = FALSE) |>
  DT::formatStyle(columns = c(1, 2, 3, 4, 5), fontSize = '75%')
```
:::

# Methodology {background-image="background_methodology.jpg"}

::: incremental
<font color='#525659'>

-   What is the experimental setting?
-   What are the techniques used?

</font>
:::

## Study area {background-image="background_thesis_study_area.jpg"}

[Experimental farm Carmejane in Digne-les-Bains (France)]{style="color:#525659"}

```{r}
#| output-location: slide
#| echo: false
library(sf)
library(tidyverse)
library(leaflet)
# Import CSV
metadata_uav_picture_map <- read_csv("metadata_uav_picture.csv")
## Tidy time and GPS
metadata_uav_picture_map <- metadata_uav_picture_map %>%
  mutate(
    GPSLatitude=round(GPSLatitude,6),
    GPSLongitude=round(GPSLongitude,6),
    CreateDate = lubridate::ymd_hms(CreateDate),
    datetime = floor_date(CreateDate, unit="hour")
  )
## Convert into sf object for leaflet
uav_gps = st_as_sf(metadata_uav_picture_map, coords = c('GPSLongitude','GPSLatitude'), crs = 4326)
sampling_area <- st_bbox(uav_gps) # current bounding box
xrange <- sampling_area$xmax - sampling_area$xmin # range of x values
yrange <- sampling_area$ymax - sampling_area$ymin # range of y values
sampling_area[1] <- sampling_area[1] - (0.30 * xrange) # xmin - left
sampling_area[3] <- sampling_area[3] + (0.30 * xrange) # xmax - right
sampling_area[2] <- sampling_area[2] - (0.30 * yrange) # ymin - bottom
sampling_area[4] <- sampling_area[4] + (0.30 * yrange) # ymax - top
# Create a sf polygon object from the sampling area
sampling_area <- sampling_area %>%  # take the bounding box ...
  st_as_sfc() # ... and make it a sf polygon
### Add polygon alpes de hayte 
communes_alpes_de_haute <-  sf::read_sf("arrondissements-04-alpes-de-haute-provence.geojson")
# Filter Digne-les-bains
digne_les_bains <- communes_alpes_de_haute %>%
            filter(nom=="Digne-les-Bains")
file <- "https://i.imgur.com/4IkevrL.jpg"
metadata_uav_picture_map <- 
  metadata_uav_picture_map |> mutate(
  image = c("https://i.imgur.com/3QOrQJO.jpg",
            "https://i.imgur.com/w1zzk4l.jpg",
            "https://i.imgur.com/h5r73u0.jpg",
            "https://i.imgur.com/l8dJKMY.jpg",
            "https://i.imgur.com/A97o8T5.jpg",
            "https://i.imgur.com/PcU8lxw.jpg",
            "https://i.imgur.com/h5r73u0.jpg"),
  scenario = as.factor(c("Pen",
               "Pasture",
               "Forest",
               "Pasture",
               "Pen",
               "Pasture",
               "Forest"))
)
scenario_pictures <- levels(metadata_uav_picture_map$scenario)
palette_scenario <- colorFactor(c("#d09455","#6bc46f","#1b75d0"),levels(metadata_uav_picture_map$scenario))
### Create leaflet
interactive_map <- leaflet() %>%
  addProviderTiles("Esri.WorldImagery", group = "Esri.WorldImagery") %>%
  addTiles(group = "HERE.hybridDayTraffic") %>%
  addProviderTiles("CartoDB.DarkMatter", group = "CartoDB.DarkMatter") %>%
  addPolygons(data = digne_les_bains, color = "steelblue", fillOpacity = 0.1) %>% 
  addPolygons(data = sampling_area, color = "blue", fillOpacity = 0) %>% 
  addCircleMarkers(data = metadata_uav_picture_map,
                   lng = ~GPSLongitude,
                   lat = ~GPSLatitude,
                   radius = 5,
                   col = ~palette_scenario(scenario),
                   popup = ~paste0("<b>UAV: </b>", DroneModel, "<br/>",
                                   "<b>Datetime: </b>", CreateDate, "<br/>",
                                   "<b>Scenario: </b>", scenario, "<br/>",
                                   "<b>GPS Altitude: </b>", GPSAltitude, "<br/>",
                                   "<b>GPS Latitude: </b>", GPSLatitude, "<br/>",
                                   "<b>GPS Longitude: </b>", GPSLongitude, "<br/>",
                                   "<b>GPS Data: </b>", FileName, "<br/>",
                                   "<img src = ", image, " width=300>")) %>%
  addLayersControl(
    baseGroups = c("Esri.WorldImagery", "HERE.hybridDayTraffic", "CartoDB.DarkMatter"),
    options = layersControlOptions(collapsed = FALSE)
  ) 
    addLegend(interactive_map, 
                data=metadata_uav_picture_map,
              position ="topright",
                values= ~scenario,
                pal = palette_scenario) |> 
  addMiniMap()

```

::: footer
Methodology
:::

## Heterogenous scenarios {background-image="background_thesis.jpg"}

![Weather conditions and landscape features characterize each of the scenarios in 3 steps](method_metadata.png){.r-stretch}

::: footer
Methodology
:::

## Model design for counting livestock {.smaller background-image="background_thesis.jpg"}

::: panel-tabset
### Model design

![Three foundation model compose the model design](model_design.png){.r-stretch background-image="background_thesis.png"}

### Image identification

![Grounding DINO identifies one sheep in images](method_image.png){.r-stretch fig-align="center" width="90%"}

### Image counting

![T-Rex counts the herd in images](method_counting.png){.r-stretch background-image="background_thesis.png" width="90%"}

### Video tracking

![SAM-PT tracks the herd in vdeo](method_video.png){.r-stretch background-image="background_thesis.png" width="85%"}
:::

::: footer
Methodology
:::

## Evaluation metrics {.smaller background-image="background_thesis.jpg"}

::: columns
::: {.column width="40%"}
```{=tex}
\begin{equation}
Mean Absolute Error (MAE) = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| 
\end{equation}
```
```{=tex}
\begin{equation}
Normalised Relative Error(NAE) = \frac{1}{n}\sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{y_i}
\end{equation}    
```
:::

::: {.column width="60%"}
![](DJI_0028.JPG){width="50%"}
:::
:::

::: footer
Methodology
:::

# Results {background-image="background_results.jpg"}

::: incremental
<font color='#525659'>

-   What are the summary results?
-   What are the techniques used?

</font>
:::

## Model generalization {background-image="background_thesis.jpg"}

![T-Rex Performance](heterogenous_scenarios_v2.png){.r-stretch}

::: footer
Results
:::

## Image counting {.smaller background-image="background_thesis.jpg"}

The model counting performance of T-Rex and YOLOv8 across the three scenarios is evaluated by the MAE. The foundation model T-Rex scores better with lower MAE than the supervised YOLOv8 model in all three scenarios.

```{r}
## For T-Rex {.smaller}
calculate_NAE <- function(ground_truth, predicted) {
  n <- length(ground_truth)
  
  if (n != length(predicted)) {
    stop("Lengths of ground_truth and predicted must be the same.")
  }
  
  nae <- sum(abs(ground_truth - predicted) / abs(ground_truth)) / n
  
  return(nae)
}
```

```{r}
library(readODS)
df_counting_trex <- read_ods("counting_v2.ods") %>%
  dplyr::rename(trex = "T-rex")
##
df_counting_trex$size_fct<- df_counting_trex$size %>% cut(c(-Inf,1924,4934,+Inf), labels=c("small","medium","big"))
# Mean Absolute Error (MAE)
## For Trex
df_counting_trex$MAE_trex <- NA
for (i in 1:nrow(df_counting_trex)) {
  df_counting_trex$MAE_trex[i] <- abs(df_counting_trex[i, "ground_truth"] - df_counting_trex[i, "trex"])
}
df_counting_trex$MAE_trex <- df_counting_trex$MAE_trex %>% unlist()
## For yolov8
df_counting_trex$MAE_yolov8 <- NA
for (i in 1:nrow(df_counting_trex)) {
  df_counting_trex$MAE_yolov8[i] <- abs(df_counting_trex[i, "ground_truth"] - df_counting_trex[i, "yolov8"])
}
df_counting_trex$MAE_yolov8 <- df_counting_trex$MAE_yolov8 %>% unlist()
# Normalized Relative Error (NAE)
# obtained from ChatGPT, manually refined.
## Populate
df_counting_trex$NAE_trex <- NA
for (i in 1:nrow(df_counting_trex)) {
  df_counting_trex$NAE_trex[i] <- round(calculate_NAE(df_counting_trex[i, "ground_truth"], df_counting_trex[i, "trex"]),2)
}

## For Yolov8
## Populate
df_counting_trex$NAE_yolov8 <- NA
for (i in 1:nrow(df_counting_trex)) {
  df_counting_trex$NAE_yolov8[i] <- round(calculate_NAE(df_counting_trex[i, "ground_truth"], df_counting_trex[i, "yolov8"]),2)
}

##
uav_weather <- read_csv("uav_videos_weather_datarame.csv")
uav_weather <- uav_weather %>%
  mutate(scenario_w = cut(hourly_cloud_cover,
                        breaks = c(-Inf,7,33,100,Inf),
                        labels = c("Sunny","Overcast","Cloudy","Error")))
uav_weather <- uav_weather %>% rename("video"="FileName")
df_alles_zusammen <- left_join(df_counting_trex, uav_weather, by="video") %>%
  mutate(ground_truth_fct =  cut(ground_truth,
                                                          breaks = c(0, 58, 216, 1028),
                                                          labels = c("Sparse", "Crowded", "Very dense")))

### outliers
quartiles <- quantile(df_alles_zusammen$ground_truth, probs=c(0.25,0.75), na.rm=FALSE)
IQR <- IQR(df_counting_trex$ground_truth)
lower <- quartiles[1] - 1.5*IQR
upper <- quartiles[2] + 1.5*IQR
df_counting_trex_no_outlier <- subset(df_alles_zusammen,df_alles_zusammen$ground_truth > lower & df_counting_trex$ground_truth < upper)
### df_counting_no_outliers long_fomrat
df_counting_trex_no_outlier_long <- df_counting_trex_no_outlier %>%     gather(key="measure",value="value",c("MAE_trex","MAE_yolov8"))
library(highcharter)
prueba_2 <- highcharter::data_to_boxplot(df_counting_trex_no_outlier_long, value, group_var = scenario, group_var2 = measure,add_outliers = FALSE , fillColor =c("#88b8b6","#dc9e9e"), color=c("#00958e","#bc7676"))

```

```{r}
highchart() %>%
    hc_xAxis(type = "category") |> 
    hc_add_series_list(prueba_2) |>
    hc_yAxis(title=list(text="Mean Absolute Error (MAE)"))

```

::: footer
Results
:::

## Image counting distribution {background-image="background_thesis.jpg"}

![T-Rex Performance](counting_performance_alluvial.jpeg){.r-stretch}

# Video tracking {background-image="background_thesis.jpg"}

## Video F1 {.r-stretch background-image="background_thesis.png"}
<br>
<font color='#525659'>A small herd in a forest with occluded sheep</font>

{{< video https://youtu.be/K43z7__fn7g?si=gDpeHta2uwBrs0R3 width="100%" height="70%" >}}

::: footer
Results
:::

## Video F2 {background-image="background_thesis.png"}

<font color='#525659'>A larger herd, and flying from a higher height made harder to detect small sheep</font>

{{< video https://youtu.be/OnXlvALXNs4?si=yfVSb0D-LtD1M-U4 width="100%" height="70%" >}}

::: footer
Results
:::

## Video P1 {background-image="background_thesis.png"}

[A small herd on pasture scenes is tracked even when the scene is recorded with zoom increments]{style="color:#525659"}

{{< video https://youtu.be/L0DTngX_iB4?si=xJSZnBs9284_FeRl width="100%" height="70%" >}}

::: footer
Results
:::

## Video P2 {background-image="background_thesis.png"}

[Even on larger herds clustered to each other, SAM-PT sucessfully tracked the detected sheep]{style="color:#525659"}

{{< video https://youtu.be/OWUjQxoQQkY?si=VWgB3hjc9lNgaDO6 >}}

::: footer
Results
:::
:::

## Result summary{background-image="background_thesis.jpg"}

::: incremental
-   T-Rex scored lower NAE & MAE values than YOLOv8
-   The size, and how crowded the herd was, influenced more the model performance than the weather conditions in this dataset
-   SAM-PT is able to track all the detected sheep with just one query point on pasture, while camouflaged and small objects taken at higher heights present a challenge.
:::

# Discusion {background-image="background_discussion.jpg"}

::: incremental
<font color='#525659'>

-   What are the answers to the research questions?
-   What are the limitations and discrepancies?

</font>
:::

## Opportunities for livestock {.smaller .incremental background-image="background_thesis.jpg"}

<font color='#525659'>Benchmarking supervised and self-supervised learning in precision livestock management</font>

To the 1st RQ: "*What are the opportunities for multi-object tracking systems to count livestock with supervised or self-supervised learning methods?*"

::: incremental
-   Both methods feasibility to count livestock depend on the scene complexity
-   Self-supervised methods, such as foundation models, can be used as annotator tools to create larger datasets for supervised methods trained to count livestock
-   Self-supervised methods, such as foundation models, can be used as a end-to-end solution carefully designing the scenario.
:::

::: footer
Discussion
:::

## Model performance {.smaller .incremental background-image="background_thesis.jpg"}

<font color='#525659'> Comparison between the supervised model YOLOv8 and the foundation model T-Rex performance on counting images </font>

To the 2nd RQ: "*How do the state-of-the-art foundation models (self-supervised) perform, when compared to previous supervised neural networks such as YOLOv8 measured by counting metrics like MAE or NAE?*"

::: incremental
-   Small, dense and camouflaged objects are challenges for both models.
-   The foundation model T-Rex performed better obtaining lower MAE and NAE error values.
-   In terms of specificity, both models mistakenly identify non-target object. Likewise, there are duplicated objects.
:::

::: footer
Discussion
:::

## Model generalization {.smaller .incremental background-image="background_thesis.jpg"}

<font color='#525659'> Influence of heterogeneous scenarios on model performance </font>

To the 3rd RQ: "*What is the model's performance on livestock counting under different weather conditions and scenarios? How much does the model generalise?*"

::: incremental
-   T-Rex generalises more than YOLOv8 in all scenarios
-   The size and how clustered the herd is is more significant than weather conditions on this data set.
-   The weather conditions were not homogeneously distributed
:::

::: footer
Discusion
:::

## State-of-the-art {.smaller background-image="background_thesis.jpg"}

::: {.smaller .incremental}
-   Contribution:
    -   Own combination of methodologies to explore foundation models released in 2023 applied on livestock
    -   Better counting performance than a supervised model
    -   Possibility to move from images counting to video tracking using foundation models
:::

::: {.smaller .incremental}
-   Products based on Grounding DINO & T-Rex are exposed in CVPR 2024, Seattle
    -   T-Rex Label: An intelligent tool designed to annotate dataset
    -   Detect Everything by text prompt: Powered by Grounding DINO 1.5
:::

::: footer
Discusion
:::

# Conclusion {.incremental background-image="background_conclussion.jpg"}

::: incremental
<font color='#525659'>

-   What is the importance of the findings?
-   What are the discovering and future implications?

</font>
:::

## Importance of findings {background-image="background_thesis.jpg"}

[Foundation models]{style="color:#525659"}

::: incremental
-   Wide range of applications without need of annotated dataset or used as a tool to increase annotated dataset. [Short-demonstration](https://colab.research.google.com/drive/1M1fLASe0aqvovRZNxd7aIgOgYiR7BcfF?usp=drive_link)
-   Challenges on supervised models also apply on foundation models
-   Simple pre-processing tasks improve the counting model performance
-   Defining a count polygon zone could be useful to use a detect and track approach instead of tracking by detection increasing the model counting performance

:::

::: footer
Conclusion
:::

## Importance of methodology {background-image="background_thesis.jpg"}

[Use of R language format Quarto and RMarkdown to write this thesis and presentation]{style="color:#525659"}

![](importance_reproducibility.png){.r-stretch}

::: footer
Conclusion
:::

## Importance of methodology
<br>
<br>



## Importance of collaboration {background-image="background_thesis.jpg"}

The original initiative to contact the team from T-Rex, Grounding DINO and T-Rex made possible to incorporate sota models in this study.

:::{.incremental}
* Mr. Lei Zhang and Mr. WeiQiang Hu from IDEA's team facilitated a T-Rex API and constant support.
* Frano Rajic solved questions regarding SAM-PT and shared valuable insights regarding future work.

:::

::: footer
Conclusion
:::

## Future implications {background-image="background_thesis.jpg"}
<font color='#525659'> The main results of the conference paper sent to AGENV2024 after submitting this thesis were: </font>

* T-Rex is able to count livestock in heights higher than 30m
* Grounding-DINO is mainly functional on 15m -30m
* The Clark-evan test to quantify clustering shown a strong negative correlation indicating its influence on the model performance

## Future implications {background-image="background_thesis.jpg"}

![]()
## Future implications 2 {background-image="background_thesis.jpg"}
<font color='#525659'> The main results of the conference paper sent to AGENV2024 after submitting this thesis were: </font>

 METER IMAGEN QUALITATIVA Y BARPLOT CLARKEVAN

::: footer
Conclusion
:::

## Thank you for attending! {background-image="background_thesis.jpg"}

<font color='#525659'> ... and also to everyone who helped me during my MSc thesis </font>

![This also includes the local goat herder in Málaga "C", who made possible to do additional research and understand their needs](SING0165.JPG){width="70%"}
